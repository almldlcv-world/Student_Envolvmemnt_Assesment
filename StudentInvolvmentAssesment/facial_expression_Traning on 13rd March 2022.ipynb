{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32298,)\n",
      "(3589,)\n",
      "(32298, 2304)\n",
      "(3589, 2304)\n",
      "x_train shape: (32298, 48, 48, 1)\n",
      "y_train shape: (32298, 3)\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "=======| Model 1 |=========\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 48, 48, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 46, 46, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 44, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 256)       147712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 18,196,487\n",
      "Trainable params: 18,193,477\n",
      "Non-trainable params: 3,010\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      " 93/404 [=====>........................] - ETA: 6:12 - loss: 1.1658 - accuracy: 0.4284"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, AveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Convolution2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Load the datasets\n",
    "data = pd.read_csv('fer2013 (11).csv', delimiter=',')#fer2013 (11)TrainLabels1\n",
    "\n",
    "# Taking Training and PublicTest data for training and PrivateTest data for testing\n",
    "data_train = data[:32298]\n",
    "data_test = data[32298:]\n",
    "# data_train.head()\n",
    "\n",
    "y_train = data_train['emotion'].values\n",
    "y_test = data_test['emotion'].values\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Converting string of pixel data to an array\n",
    "x_train = np.zeros((y_train.shape[0], 48*48))\n",
    "for i in range(y_train.shape[0]):\n",
    "    x_train[i] = np.fromstring(data_train['pixels'][i], dtype=int, sep=' ')\n",
    "\n",
    "x_test = np.zeros((y_test.shape[0], 48*48))\n",
    "for i in range(y_test.shape[0]):\n",
    "    x_test[i] = np.fromstring(data_test['pixels'][32298+i], dtype=int, sep=' ')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Generate reversed images for every data assuming emotion are symetric\n",
    "img_rows, img_cols = 48, 48\n",
    "num_classes = 3  #7\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train_rev = np.flip(x_train, 2)\n",
    "x_test_rev = np.flip(x_test, 2)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(x_train[0].reshape((48,48)))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(x_train_rev[0].reshape((48,48)))\n",
    "\n",
    "# Some preprocessing\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train_rev = x_train_rev.astype('float32')\n",
    "x_test_rev = x_test_rev.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train_rev /= 255\n",
    "x_test_rev /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# define the model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "# model.summary()\n",
    "def cnn_modell():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                                name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax',name='predictions'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "# function to plot graph\n",
    "def plotGraph(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "# We will train two models one on normal images another on reversed images and finally a NN on predicted values from these models\n",
    "import os \n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20 #25\n",
    "model = []\n",
    "\n",
    "print(\"=======| Model 1 |=========\")\n",
    "modelc = cnn_model()\n",
    "history = modelc.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.2)\n",
    "model.append(modelc)\n",
    "plotGraph(history)\n",
    "\n",
    "print(\"=======| Model 2 |=========\")\n",
    "modelb = cnn_modell()\n",
    "history = modelc.fit(x_train_rev, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1)\n",
    "model.append(modelb)\n",
    "plotGraph(history)\n",
    "\n",
    "# p_tr >> prediction on training data\n",
    "# p_te >> prediction on test data\n",
    "\n",
    "p_tr = []\n",
    "p_te = []\n",
    "\n",
    "for i, m in enumerate(model):\n",
    "    if i ==0:\n",
    "        p = m.predict(x_train)\n",
    "        pt = m.predict(x_test)\n",
    "    else:\n",
    "        p = m.predict(x_train_rev)\n",
    "        pt = m.predict(x_test_rev)\n",
    "    p_tr.append(p)\n",
    "    p_te.append(pt)\n",
    "    m.save('saved_modell/cnn'+str(i)+'.h5')\n",
    "\n",
    "print(len(model))\n",
    "\n",
    "p_train = np.zeros((y_train.shape[0],num_classes*len(model)))\n",
    "p_test = np.zeros((y_test.shape[0],num_classes*len(model)))\n",
    "for i, p in enumerate(p_tr):\n",
    "    print(i)\n",
    "    p_train[:,num_classes*i:num_classes*(i+1)] = p\n",
    "\n",
    "for i, p in enumerate(p_te):\n",
    "    p_test[:,num_classes*i:num_classes*(i+1)] = p\n",
    "\n",
    "print(p_train.shape, p_test.shape)\n",
    "\n",
    "# Trains an Conventional Neural Network on previously predicted values by the two models\n",
    "\n",
    "batch_size = 64 #32\n",
    "num_classes = 3\n",
    "epochs = 3\n",
    "\n",
    "modele = Sequential()\n",
    "modele.add(Dense(128, activation='relu', input_shape=(num_classes*len(model),)))\n",
    "modele.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "modele.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = modele.fit(p_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(p_test, y_test))\n",
    "\n",
    "score = modele.evaluate(p_test, y_test, verbose=0)\n",
    "modele.save('saved_modell/ensemble.h5')\n",
    "\n",
    "print('NN Based Ensembled Model')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063971e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n",
      "(1358,)\n",
      "(4000, 2304)\n",
      "(1358, 2304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-2c7a07a3dca4>:43: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  x_train[i] = np.fromstring(data_train['ClipID'][i], dtype=int, sep=' ')\n",
      "<ipython-input-1-2c7a07a3dca4>:47: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  x_test[i] = np.fromstring(data_test['ClipID'][4000+i], dtype=int, sep=' ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4000, 48, 48, 1)\n",
      "y_train shape: (4000, 4)\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "=======| Model 1 |=========\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 33s 618ms/step - loss: 0.9569 - accuracy: 0.6778 - val_loss: 0.8246 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "26/50 [==============>...............] - ETA: 13s - loss: 0.8018 - accuracy: 0.7542"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load the datasets\n",
    "data = pd.read_csv('TrainLabels1.csv', delimiter=',')#fer2013 (11)TrainLabels1\n",
    "\n",
    "# Taking Training and PublicTest data for training and PrivateTest data for testing\n",
    "data_train = data[:4000]\n",
    "data_test = data[4000:]\n",
    "# data_train.head()\n",
    "\n",
    "y_train = data_train['emotion'].values\n",
    "y_test = data_test['emotion'].values\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Converting string of pixel data to an array\n",
    "x_train = np.zeros((y_train.shape[0], 48*48))\n",
    "for i in range(y_train.shape[0]):\n",
    "    x_train[i] = np.fromstring(data_train['ClipID'][i], dtype=int, sep=' ')\n",
    "\n",
    "x_test = np.zeros((y_test.shape[0], 48*48))\n",
    "for i in range(y_test.shape[0]):\n",
    "    x_test[i] = np.fromstring(data_test['ClipID'][4000+i], dtype=int, sep=' ')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Generate reversed images for every data assuming emotion are symetric\n",
    "img_rows, img_cols = 48, 48\n",
    "num_classes = 4  #7\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train_rev = np.flip(x_train, 2)\n",
    "x_test_rev = np.flip(x_test, 2)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(x_train[0].reshape((48,48)))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(x_train_rev[0].reshape((48,48)))\n",
    "\n",
    "# Some preprocessing\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train_rev = x_train_rev.astype('float32')\n",
    "x_test_rev = x_test_rev.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train_rev /= 255\n",
    "x_test_rev /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# define the model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    # model.add(Conv2D(32, (3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# function to plot graph\n",
    "def plotGraph(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "# We will train two models one on normal images another on reversed images and finally a NN on predicted values from these models\n",
    "import os \n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model = []\n",
    "\n",
    "print(\"=======| Model 1 |=========\")\n",
    "modelc = cnn_model()\n",
    "history = modelc.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.2)\n",
    "model.append(modelc)\n",
    "plotGraph(history)\n",
    "\n",
    "print(\"=======| Model 2 |=========\")\n",
    "modelc = cnn_model()\n",
    "history = modelc.fit(x_train_rev, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1)\n",
    "model.append(modelc)\n",
    "plotGraph(history)\n",
    "\n",
    "# p_tr >> prediction on training data\n",
    "# p_te >> prediction on test data\n",
    "\n",
    "p_tr = []\n",
    "p_te = []\n",
    "\n",
    "for i, m in enumerate(model):\n",
    "    if i ==0:\n",
    "        p = m.predict(x_train)\n",
    "        pt = m.predict(x_test)\n",
    "    else:\n",
    "        p = m.predict(x_train_rev)\n",
    "        pt = m.predict(x_test_rev)\n",
    "    p_tr.append(p)\n",
    "    p_te.append(pt)\n",
    "    m.save('saved_modell/cnn'+str(i)+'.h5')\n",
    "\n",
    "print(len(model))\n",
    "\n",
    "p_train = np.zeros((y_train.shape[0],num_classes*len(model)))\n",
    "p_test = np.zeros((y_test.shape[0],num_classes*len(model)))\n",
    "for i, p in enumerate(p_tr):\n",
    "    print(i)\n",
    "    p_train[:,num_classes*i:num_classes*(i+1)] = p\n",
    "\n",
    "for i, p in enumerate(p_te):\n",
    "    p_test[:,num_classes*i:num_classes*(i+1)] = p\n",
    "\n",
    "print(p_train.shape, p_test.shape)\n",
    "\n",
    "# Trains an Conventional Neural Network on previously predicted values by the two models\n",
    "\n",
    "batch_size = 64 #32\n",
    "num_classes = 4\n",
    "epochs = 10\n",
    "\n",
    "modele = Sequential()\n",
    "modele.add(Dense(128, activation='relu', input_shape=(num_classes*len(model),)))\n",
    "modele.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "modele.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = modele.fit(p_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(p_test, y_test))\n",
    "\n",
    "score = modele.evaluate(p_test, y_test, verbose=0)\n",
    "modele.save('saved_modell/ensemble.h5')\n",
    "\n",
    "print('NN Based Ensembled Model')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71d010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
